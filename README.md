
# üöÄ CampAIgn Analytics

> **An end-to-end A/B testing analytics pipeline that cleans campaign data, loads it into SQLite, computes KPIs, generates interactive visualizations, and delivers AI-powered PDF and PPTX reports to identify the winning campaign.**

---

## üìñ Table of Contents
1. [Introduction](#introduction)  
2. [Dataset](#dataset)  
3. [Project Workflow](#project-workflow)  
4. [Folder Structure](#folder-structure)  
5. [SQL Workflow](#sql-workflow)  
6. [Python Pipeline](#python-pipeline)  
7. [Notebooks & Visualizations](#notebooks--visualizations)  
8. [Results & Insights](#results--insights)  
9. [Tech Stack](#tech-stack)  
10. [Setup Instructions](#setup-instructions)  
11. [Future Improvements](#future-improvements)  
12. [License](#license)  

---

## üîç Introduction

**CampAIgn Analytics** is an end-to-end  **A/B intelligent testing pipeline** that empowers marketing teams to make data-driven campaign decisions with speed and confidence.

Instead of just comparing raw metrics, this system delivers a fully automated workflow that:

- **Cleans & processes** campaign data with **Python**, ensuring reliability at scale.

- **Computes reproducible KPIs (CTR, CPC, CPA, CPM, Conversion Rate) using SQL & SQLite** for analytical rigor.

- **Generates interactive visualizations** with **Plotly & Jupyter**, enabling stakeholders to explore insights intuitively.

- **Delivers stakeholder-ready reports** in **PDF & PPTX**, enhanced with **AI-generated executive summaries and actionable recommendations**.

‚ö° In short, CampAIgn Analytics transforms raw marketing data into clear business outcomes, helping organizations identify the winning campaign and optimize ROI‚Äîall in one pipeline.

üí° This project demonstrates qualities like scale‚Äîautomation, reproducibility, and AI-powered decision intelligence‚Äîmaking it directly relevant to solving large-scale data challenges in industry.

    
## üìÇ Dataset

The project is designed around a realistic digital marketing dataset, structured to mirror how enterprises manage campaign analytics pipelines.

- **Raw dataset (`data/raw/campaign_data.csv`)**
  - Captures end-to-end campaign performance metrics:
    - `Campaign Name, Date, Spend [USD], # of Impressions, Reach, # of Website Clicks, # of Searches, # of View Content, # of Add to Cart, # of Purchase`


    <img width="836" height="854" alt="campaign_data" src="https://github.com/user-attachments/assets/20cd3f18-d537-457a-9592-46620b99818a" />
    

- **Processed dataset (`data/processed/cleaned_campaign.csv`)**
  - Automatically generated via loader.py + cleaner.py.
  - Enhancements applied:
    - Standardized headers & enforced datatypes
    - Removal of invalid or incomplete rows
    - Normalized format to ensure reproducibility
  - Acts as the ‚Äúsingle source of truth‚Äù for all downstream analysis.
  -  - `group` indicates Control (**A**) vs Test (**B**)
  - The group field differentiates Control (A) vs Test (B) cohorts, enabling rigorous A/B testing.
    
    <img width="719" height="727" alt="clean_campaign" src="https://github.com/user-attachments/assets/8e93b498-152f-49d2-a632-5d05dd6948c8" />


‚ú® This structured data pipeline highlights best practices in data engineering‚Äîensuring clean, validated, and analysis-ready datasets.


---
## üèóÔ∏è Architecture Overview

CampAIgn Analytics follows a modular, production-grade architecture designed for clarity, scalability, and automation.

```

CampAIgn-Analytics/
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ raw/
‚îÇ  ‚îÇ  ‚îî‚îÄ campaign_data.csv
‚îÇ  ‚îî‚îÄ processed/
‚îÇ     ‚îî‚îÄ cleaned_campaign.csv
‚îÇ
‚îú‚îÄ dbms/                      # SQL workflow
‚îÇ  ‚îú‚îÄ create_table.sql
‚îÇ  ‚îú‚îÄ cleanup_and_reload.sql
‚îÇ  ‚îú‚îÄ sanity_checks.sql
‚îÇ  ‚îú‚îÄ metrics_calculation.sql
‚îÇ  ‚îú‚îÄ ab_summary.sql
‚îÇ  ‚îú‚îÄ daily_trends.sql
‚îÇ  ‚îî‚îÄ create_views.sql
‚îÇ
‚îú‚îÄ src/                       # Python package (run: python -m src.pipeline)
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ pipe.py
‚îÇ  ‚îú‚îÄ data_processing/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ loader.py
‚îÇ  ‚îÇ  ‚îî‚îÄ cleaner.py
‚îÇ  ‚îú‚îÄ analysis_engine/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ metrics.py
‚îÇ  ‚îÇ  ‚îú‚îÄ statistic_test.py
‚îÇ  ‚îÇ  ‚îî‚îÄ visualization.py
‚îÇ  ‚îî‚îÄ reporting/
‚îÇ     ‚îú‚îÄ __init__.py
‚îÇ     ‚îú‚îÄ ai_report.py
‚îÇ     ‚îî‚îÄ export.py
‚îÇ 
‚îú‚îÄ notebook/
‚îÇ  ‚îú‚îÄ chart
‚îÇ  |  ‚îú‚îÄ ts_purchases_by_group.html
‚îÇ  |  ‚îú‚îÄ ts_impressions_by_group.html
‚îÇ  |  ‚îú‚îÄ ts_spend_by_group.html
‚îÇ  |  ‚îú‚îÄ ts_clicks_by_group.html
‚îÇ  |  ‚îú‚îÄ funnel_group_A.html
‚îÇ  |  ‚îú‚îÄ funnel_group_B.html
‚îÇ  |  ‚îú‚îÄ pie_spend_vs_purchases_group_A.html
‚îÇ  |  ‚îî‚îÄ pie_spend_vs_purchases_group_B.html
   |‚îÄ chart_image
‚îÇ  |  ‚îú‚îÄ ts_purchases_by_group.png
‚îÇ  |  ‚îú‚îÄ ts_impressions_by_group.png
‚îÇ  |  ‚îú‚îÄ ts_spend_by_group.png
‚îÇ  |  ‚îú‚îÄ ts_clicks_by_group.png
‚îÇ  |  ‚îú‚îÄ funnel_group_A.png
‚îÇ  |  ‚îú‚îÄ funnel_group_B.png
‚îÇ  |  ‚îú‚îÄ pie_spend_vs_purchases_group_A.png
‚îÇ  |  ‚îî‚îÄ pie_spend_vs_purchases_group_B.png
‚îÇ  ‚îî‚îÄ visualisation.ipynb
‚îÇ
‚îú‚îÄ reports/
‚îÇ  ‚îú‚îÄ charts/
‚îÇ  ‚îÇ  ‚îú‚îÄ conversion_rate_by_group.png
‚îÇ  ‚îÇ  ‚îú‚îÄ revenue_distribution.png
‚îÇ  ‚îÇ  ‚îú‚îÄ roi_comparison.png
‚îÇ  ‚îÇ  ‚îú‚îÄ ts_purchases_by_group.png
‚îÇ  ‚îÇ  ‚îú‚îÄ ts_impressions_by_group.png
‚îÇ  ‚îÇ  ‚îú‚îÄ ts_spend_by_group.png
‚îÇ  ‚îÇ  ‚îú‚îÄ ts_clicks_by_group.png
‚îÇ  ‚îÇ  ‚îú‚îÄ funnel_group_A.png
‚îÇ  ‚îÇ  ‚îú‚îÄ funnel_group_B.png
‚îÇ  ‚îÇ  ‚îú‚îÄ pie_spend_vs_purchases_group_A.png
‚îÇ  ‚îÇ  ‚îî‚îÄ pie_spend_vs_purchases_group_B.png
‚îÇ  ‚îú‚îÄ final_report.pdf
‚îÇ  ‚îî‚îÄ final_report.pptx
‚îÇ
‚îú‚îÄ sql.db                     # SQLite database (often gitignored)
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
```
**üîé Layer-by-Layer Purpose**
- data/ ‚Üí Stores raw campaign CSVs and cleaned datasets (single source of truth).
- dbms/ ‚Üí SQL layer ensures reproducible KPI computation and analytical rigor.
- src/ ‚Üí Python package for data processing, statistical testing, visualization, and AI   reporting.
- notebook/ ‚Üí Sandbox for interactive exploration and chart prototyping.
- reports/ ‚Üí Automatically generated executive-ready deliverables in PDF & PPTX format.
- sql.db ‚Üí Lightweight database for portability & reproducibility.

üí° This architecture demonstrates a full **data engineering + analytics pipeline**: from raw data ingestion to AI-generated business insights

## üîÑ Project Workflow

CampAIgn Analytics runs as a fully automated pipeline that transforms raw campaign data into executive-ready insights and reports.

**‚ö° Step-by-Step Flow**

**1. üì• Data Ingestion:**  
      - Raw campaign CSVs ingested.  
      - Processed into a clean CSV `(data/processed/cleaned_campaign.csv)` with standardized schema & datatypes.

**2. üóÑÔ∏è Database Loading:**  
      - SQLite tables created via `create_table.sql`.  
      - Cleaned data loaded into `sql.db` for reproducibility and fast queries.

**3. ‚úÖ Sanity Checks:**  
      - Validations ensure data integrity:  
        - Row counts match  
        - Nulls handled  
        - Date ranges consistent  
        - Control/Test group distribution verified  

**4. üìä KPI Calculation:**  
     - Core performance metrics computed directly in SQL:  
         - CTR (Click-Through Rate)  
         - Conversion Rate  
         - CPC (Cost per Click)  
         - CPA (Cost per Acquisition)  
         - CPM (Cost per Mille/1000 Impressions)  

**5. üîç Analysis & Summary:**   
    - Statistical testing identifies the winning group (A or B).   
    - Lift analysis quantifies improvement over the control.  

**6. üìà Visualizations:**  
    - Interactive Plotly dashboards:  
        - Time-series trends  
        - Funnel analysis  
        - Spend vs Purchases breakdown (Pie charts)  

**7. ü§ñ AI-Generated Reporting:**   
   - Pipeline produces PDF & PPTX reports with:  
        - Charts embedded  
        - Natural-language executive summaries  
        - Clear business recommendations    

üí° This workflow reflects a production-grade analytics system: data validation, reproducibility, statistical rigor, visualization, and AI-enhanced reporting.

---

## üóÑÔ∏è SQL Workflow
- **`create_table.sql`**  
  Creates:  
  - `raw_campaign_data` (staging; mirrors CSV headers for `.import`)  
  - `campaign_data` (normalized; SQL-friendly columns & types)

- **`cleanup_and_reload.sql`**  
  Clears old data, imports `cleaned_campaign.csv` into staging, drops header rows if any, inserts **distinct** rows into `campaign_data`, and prints counts.

- **`sanity_checks.sql`**  
  Validates row counts, date range, nulls, and group distribution.

- **`metrics_calculation.sql`**  
  Group-level KPIs: CTR, Conversion Rate, CPC, CPA, CPM, and funnel step rates.

- **`ab_summary.sql`**  
  Side-by-side comparison of groups with lift metrics and a simple winner decision.

- **`daily_trends.sql`**  
  Time-series KPIs (CTR & Conversion) per group for drift/ramp-up detection.

- **`create_views.sql`**  
  Reusable views:  
  - `vw_group_kpis` (overall KPIs by group)  
  - `vw_daily_kpis` (daily breakdown by group)

---

## üêç Python Pipeline
- **`pipe.py`** ‚Äî Orchestrator that:
  - Runs data cleaning & loading  
  - Executes SQL workflows  
  - Computes KPIs & trends  
  - Generates Plotly charts  
  - Produces AI-written insights  
  - Exports **PDF** and **PPTX** reports to `reports/`

- **`data_processing/`**
  - `loader.py` ‚Äî Loads raw CSV ‚Üí SQLite staging table.  
  - `cleaner.py` ‚Äî Cleans & standardizes dataset ‚Üí `data/processed/cleaned_campaign.csv`.

- **`analysis_engine/`**
  - `metrics.py` ‚Äî Python-side KPIs (optional; mirrors SQL).  
  - `statistic_test.py` ‚Äî Significance testing (e.g., chi-square/t-tests).  
  - `visualization.py` ‚Äî Plotly charts saved to `reports/charts/`.

- **`reporting/`**
  - `ai_report.py` ‚Äî Generates narrative insights with AI.  
  - `exporter.py` ‚Äî Compiles charts + insights ‚Üí **PDF/PPTX**.

---

## üìì Notebooks & Visualizations
- **`visualisation.ipynb`** ‚Äî Interactive Plotly visuals (saved as HTML for sharing).  

**Interactive HTML charts (open in browser):**
- Time Series  
  - [Impressions Over Time](notebook/chart_image/ts_impressions_by_group.png)  
  - [Spend Over Time](notebook/chart_image/ts_spend_by_group.png)  
  - [Purchases Over Time](notebook/chart_image/ts_purchases_by_group.png)  
  - [Website Clicks Over Time](reports/chart_image/ts_clicks_by_group.png)  
- Composition (Spend vs Purchases)  
  - [Group A](notebook/chart_image/pie_spend_vs_purchases_A.png)  
  - [Group B](notebook/chart_image/pie_spend_vs_purchases_B.png)  
- Funnels  
  - [Conversion Funnel ‚Äî Group A](notebook/chart_image/funnel_group_A.png)  
  - [Conversion Funnel ‚Äî Group B](notebook/chart_image/funnel_group_B.png)

> GitHub shows notebook outputs as **static previews**. These HTML files keep full **Plotly interactivity** (zoom, hover, toggle series) when opened locally or via a static server.

---

## üìà Results & Insights
- **Group B** consistently outperformed **Group A**:
  - Higher **Conversion Rate** (‚âà +10%)  
  - Lower **Cost per Acquisition (CPA)**  
- Funnel analysis shows **A** drops more between *View Content ‚Üí Add to Cart*.  
- **Recommendation:** allocate more budget to **B**; optimize mid-funnel for **A**.


## üõ† Tech Stack
- **Python 3.10+** ‚Äî pandas, plotly, matplotlib, seaborn  
- **SQLite 3.4+** ‚Äî SQL-first KPI computation & views  
- **VS Code** ‚Äî with **SQLite3 Editor** extension for grid outputs  
- **Jupyter Notebooks** ‚Äî EDA & interactive charts  
- **AI Reporting** ‚Äî automated insights + **PDF/PPTX** export

---

## ‚öôÔ∏è Setup Instructions

1. **Clone the repo**   

       git clone https://github.com/cathelenegeorge/CampAIgn-Analytics.gitcd CampAIgn-Analytics

3. **Create a virtual environment**

       -python -m venv venv   
       -source venv/bin/activate   # Mac/Linux     
       -venv\Scripts\activate      # Windows  
       -pip install -r requirements.txt


4. **Create database schema**

       -sqlite3 sql.db ".read dbms/create_table.sql"


5. **Load cleaned dataset**

       -sqlite3 sql.db ".read dbms/cleanup_and_reload.sql"


6. **Run sanity checks**

       -sqlite3 -header -column sql.db ".read dbms/sanity_checks.sql"


7. **Run full pipeline**

        -python -m src.pipeline


Open interactive visuals

Open the PNG files under notebook/chart_image/ see the links above!.

