
# ğŸš€ CampAIgn Analytics

> **An end-to-end A/B testing analytics pipeline that cleans campaign data, loads it into SQLite, computes KPIs, generates interactive visualizations, and delivers AI-powered PDF and PPTX reports to identify the winning campaign.**

---

## ğŸ“– Table of Contents
1. [Introduction](#introduction)  
2. [Dataset](#dataset)  
3. [Project Workflow](#project-workflow)  
4. [Folder Structure](#folder-structure)  
5. [SQL Workflow](#sql-workflow)  
6. [Python Pipeline](#python-pipeline)  
7. [Notebooks & Visualizations](#notebooks--visualizations)  
8. [Results & Insights](#results--insights)  
9. [Tech Stack](#tech-stack)  
10. [Setup Instructions](#setup-instructions)  
11. [Future Improvements](#future-improvements)  
12. [License](#license)  

---

## ğŸ” Introduction

**CampAIgn Analytics** is an end-to-end  **A/B intelligent testing pipeline** that empowers marketing teams to make data-driven campaign decisions with speed and confidence.

Instead of just comparing raw metrics, this system delivers a fully automated workflow that:

- **Cleans & processes** campaign data with **Python**, ensuring reliability at scale.

- **Computes reproducible KPIs (CTR, CPC, CPA, CPM, Conversion Rate) using SQL & SQLite** for analytical rigor.

- **Generates interactive visualizations** with **Plotly & Jupyter**, enabling stakeholders to explore insights intuitively.

- **Delivers stakeholder-ready reports** in **PDF & PPTX**, enhanced with **AI-generated executive summaries and actionable recommendations**.

âš¡ In short, CampAIgn Analytics transforms raw marketing data into clear business outcomes, helping organizations identify the winning campaign and optimize ROIâ€”all in one pipeline.

ğŸ’¡ This project demonstrates qualities like scaleâ€”automation, reproducibility, and AI-powered decision intelligenceâ€”making it directly relevant to solving large-scale data challenges in industry.

    
## ğŸ“‚ Dataset

The project is designed around a realistic digital marketing dataset, structured to mirror how enterprises manage campaign analytics pipelines.

- **Raw dataset (`data/raw/campaign_data.csv`)**
  - Captures end-to-end campaign performance metrics:
    - `Campaign Name, Date, Spend [USD], # of Impressions, Reach, # of Website Clicks, # of Searches, # of View Content, # of Add to Cart, # of Purchase`


    <img width="836" height="854" alt="campaign_data" src="https://github.com/user-attachments/assets/20cd3f18-d537-457a-9592-46620b99818a" />
    

- **Processed dataset (`data/processed/cleaned_campaign.csv`)**
  - Automatically generated via loader.py + cleaner.py.
  - Enhancements applied:
    - Standardized headers & enforced datatypes
    - Removal of invalid or incomplete rows
    - Normalized format to ensure reproducibility
  - Acts as the â€œsingle source of truthâ€ for all downstream analysis.
  -  - `group` indicates Control (**A**) vs Test (**B**)
  - The group field differentiates Control (A) vs Test (B) cohorts, enabling rigorous A/B testing.
    
    <img width="719" height="727" alt="clean_campaign" src="https://github.com/user-attachments/assets/8e93b498-152f-49d2-a632-5d05dd6948c8" />


âœ¨ This structured data pipeline highlights best practices in data engineeringâ€”ensuring clean, validated, and analysis-ready datasets.


---
## ğŸ—ï¸ Architecture Overview

CampAIgn Analytics follows a modular, production-grade architecture designed for clarity, scalability, and automation.

```

CampAIgn-Analytics/
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”‚  â””â”€ campaign_data.csv
â”‚  â””â”€ processed/
â”‚     â””â”€ cleaned_campaign.csv
â”‚
â”œâ”€ dbms/                      # SQL workflow
â”‚  â”œâ”€ create_table.sql
â”‚  â”œâ”€ cleanup_and_reload.sql
â”‚  â”œâ”€ sanity_checks.sql
â”‚  â”œâ”€ metrics_calculation.sql
â”‚  â”œâ”€ ab_summary.sql
â”‚  â”œâ”€ daily_trends.sql
â”‚  â””â”€ create_views.sql
â”‚
â”œâ”€ src/                       # Python package (run: python -m src.pipeline)
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ pipe.py
â”‚  â”œâ”€ data_processing/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ loader.py
â”‚  â”‚  â””â”€ cleaner.py
â”‚  â”œâ”€ analysis_engine/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ metrics.py
â”‚  â”‚  â”œâ”€ statistic_test.py
â”‚  â”‚  â””â”€ visualization.py
â”‚  â””â”€ reporting/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ ai_report.py
â”‚     â””â”€ export.py
â”‚ 
â”œâ”€ notebook/
â”‚  â”œâ”€ chart
â”‚  |  â”œâ”€ ts_purchases_by_group.html
â”‚  |  â”œâ”€ ts_impressions_by_group.html
â”‚  |  â”œâ”€ ts_spend_by_group.html
â”‚  |  â”œâ”€ ts_clicks_by_group.html
â”‚  |  â”œâ”€ funnel_group_A.html
â”‚  |  â”œâ”€ funnel_group_B.html
â”‚  |  â”œâ”€ pie_spend_vs_purchases_group_A.html
â”‚  |  â””â”€ pie_spend_vs_purchases_group_B.html
   |â”€ chart_image
â”‚  |  â”œâ”€ ts_purchases_by_group.png
â”‚  |  â”œâ”€ ts_impressions_by_group.png
â”‚  |  â”œâ”€ ts_spend_by_group.png
â”‚  |  â”œâ”€ ts_clicks_by_group.png
â”‚  |  â”œâ”€ funnel_group_A.png
â”‚  |  â”œâ”€ funnel_group_B.png
â”‚  |  â”œâ”€ pie_spend_vs_purchases_group_A.png
â”‚  |  â””â”€ pie_spend_vs_purchases_group_B.png
â”‚  â””â”€ visualisation.ipynb
â”‚
â”œâ”€ reports/
â”‚  â”œâ”€ charts/
â”‚  â”‚  â”œâ”€ conversion_rate_by_group.png
â”‚  â”‚  â”œâ”€ revenue_distribution.png
â”‚  â”‚  â”œâ”€ roi_comparison.png
â”‚  â”‚  â”œâ”€ ts_purchases_by_group.png
â”‚  â”‚  â”œâ”€ ts_impressions_by_group.png
â”‚  â”‚  â”œâ”€ ts_spend_by_group.png
â”‚  â”‚  â”œâ”€ ts_clicks_by_group.png
â”‚  â”‚  â”œâ”€ funnel_group_A.png
â”‚  â”‚  â”œâ”€ funnel_group_B.png
â”‚  â”‚  â”œâ”€ pie_spend_vs_purchases_group_A.png
â”‚  â”‚  â””â”€ pie_spend_vs_purchases_group_B.png
â”‚  â”œâ”€ final_report.pdf
â”‚  â””â”€ final_report.pptx
â”‚
â”œâ”€ sql.db                     # SQLite database (often gitignored)
â”œâ”€ requirements.txt
â””â”€ README.md
```
**ğŸ” Layer-by-Layer Purpose**
- data/ â†’ Stores raw campaign CSVs and cleaned datasets (single source of truth).
- dbms/ â†’ SQL layer ensures reproducible KPI computation and analytical rigor.
- src/ â†’ Python package for data processing, statistical testing, visualization, and AI   reporting.
- notebook/ â†’ Sandbox for interactive exploration and chart prototyping.
- reports/ â†’ Automatically generated executive-ready deliverables in PDF & PPTX format.
- sql.db â†’ Lightweight database for portability & reproducibility.

ğŸ’¡ This architecture demonstrates a full **data engineering + analytics pipeline**: from raw data ingestion to AI-generated business insights

## ğŸ”„ Project Workflow

CampAIgn Analytics runs as a fully automated pipeline that transforms raw campaign data into executive-ready insights and reports.

**âš¡ Step-by-Step Flow**

**1. ğŸ“¥ Data Ingestion:**  
- Raw campaign CSVs ingested.  
- Processed into a clean CSV `(data/processed/cleaned_campaign.csv)` with standardized schema & datatypes.

**2. ğŸ—„ï¸ Database Loading:**  
- SQLite tables created via `create_table.sql`.  
- Cleaned data loaded into `sql.db` for reproducibility and fast queries.

**3. âœ… Sanity Checks:**  
- Validations ensure data integrity:  
  - Row counts match  
  - Nulls handled  
  - Date ranges consistent  
  - Control/Test group distribution verified  

**4. ğŸ“Š KPI Calculation:**  
- Core performance metrics computed directly in SQL:  
  - CTR (Click-Through Rate)  
  - Conversion Rate  
  - CPC (Cost per Click)  
  - CPA (Cost per Acquisition)  
  - CPM (Cost per Mille/1000 Impressions)  

**5. ğŸ” Analysis & Summary:**   
- Statistical testing identifies the winning group (A or B).   
- Lift analysis quantifies improvement over the control.  

**6. ğŸ“ˆ Visualizations:**  
- Interactive Plotly dashboards:  
  - Time-series trends  
  - Funnel analysis  
  - Spend vs Purchases breakdown (Pie charts)  

**7. ğŸ¤– AI-Generated Reporting:**   
- Pipeline produces PDF & PPTX reports with:  
  - Charts embedded  
  - Natural-language executive summaries  
  - Clear business recommendations    

ğŸ’¡ This workflow reflects a production-grade analytics system: data validation, reproducibility, statistical rigor, visualization, and AI-enhanced reporting.

---

## ğŸ“œ Core SQL Scripts  

### **`create_table.sql`**  
âœ… Defines schema for:  
- **`raw_campaign_data`** â†’ staging layer that mirrors raw CSV headers (for direct `.import`).  
- **`campaign_data`** â†’ normalized analysis table with SQL-friendly columns & types.  

ğŸ”¹ **Why it matters:** Establishes a **clean separation** between raw input and normalized, analysis-ready data.  

---

### **`cleanup_and_reload.sql`**  
âœ… Automates:  
- Clearing stale data  
- Importing fresh `cleaned_campaign.csv` into staging  
- Dropping header rows if present  
- Inserting **deduplicated rows** into `campaign_data`  
- Printing row counts for validation  

ğŸ”¹ **Why it matters:** Guarantees **data freshness, consistency, and deduplication** at every run.  

---

### **`sanity_checks.sql`**  
âœ… Validates:  
- Row counts  
- Null handling  
- Date range alignment  
- Control vs Test group distribution  

ğŸ”¹ **Why it matters:** Ensures **data integrity** before downstream KPI calculations.  

---

### **`metrics_calculation.sql`**  
âœ… Computes **group-level KPIs**:  
- CTR (Click-Through Rate)  
- Conversion Rate  
- CPC (Cost per Click)  
- CPA (Cost per Acquisition)  
- CPM (Cost per Mille)  
- Funnel step conversion rates  

ğŸ”¹ **Why it matters:** Provides the **quantitative backbone** for campaign comparison.  

---

### **`ab_summary.sql`**  
âœ… Delivers **side-by-side comparison** of Group A vs Group B with:  
- Lift metrics  
- Winner declaration (best performing group)  

ğŸ”¹ **Why it matters:** Converts KPIs into a **direct decision framework** for marketing teams.  

---

### **`daily_trends.sql`**  
âœ… Generates **time-series KPIs** (CTR & Conversion) per group.  

ğŸ”¹ **Why it matters:** Detects **performance drift, learning effects, or ramp-up trends**.  

---

### **`create_views.sql`**  
âœ… Defines **reusable views**:  
- `vw_group_kpis` â†’ Overall KPIs by group  
- `vw_daily_kpis` â†’ Daily breakdown by group  

ğŸ”¹ **Why it matters:** Simplifies queries for analysts & integrates cleanly into the **Python pipeline**.  

ğŸ’¡ This **SQL workflow** demonstrates **data engineering best practicesâ€”staging, normalization, validation, reproducible KPIs, and reusable viewsâ€”mirroring the scalable, audit-ready pipelines**

---

## ğŸ Python Pipeline  

The **Python layer** acts as the **orchestrator** of the entire workflow â€” connecting data ingestion, SQL analytics, visualization, and AI-powered reporting into one seamless pipeline.  

---

### **`pipe.py`** â€“ Orchestrator  
âœ… Executes the full pipeline:  
- Runs **data cleaning & loading**  
- Executes **SQL workflows**  
- Computes **KPIs & trends**  
- Generates **Plotly charts**  
- Produces **AI-written insights**  
- Exports **PDF & PPTX reports** into `reports/`  

ğŸ”¹ **Why it matters:** Serves as the **automation backbone**, ensuring reproducibility and one-command execution.  

---

### ğŸ“‚ **`data_processing/`**  

- **`loader.py`**  
  âœ… Loads raw CSV â†’ SQLite staging table.  
  ğŸ”¹ *Guarantees smooth ingestion of new campaign data.*  

- **`cleaner.py`**  
  âœ… Cleans & standardizes dataset â†’ `data/processed/cleaned_campaign.csv`.  
  ğŸ”¹ *Provides a reliable â€œsingle source of truthâ€ for analysis.*  

---

### ğŸ“‚ **`analysis_engine/`**  

- **`metrics.py`**  
  âœ… Computes Python-side KPIs (mirrors SQL).  
  ğŸ”¹ *Adds flexibility for analysts preferring Python over SQL.*  

- **`statistic_test.py`**  
  âœ… Performs significance testing (chi-square, t-tests).  
  ğŸ”¹ *Enables **statistical rigor** in A/B testing decisions.*  

- **`visualization.py`**  
  âœ… Builds Plotly charts â†’ saved into `reports/charts/`.  
  ğŸ”¹ *Transforms metrics into **interactive, decision-friendly visuals**.*  

---

### ğŸ“‚ **`reporting/`**  

- **`ai_report.py`**  
  âœ… Generates **natural-language insights** using AI.  
  ğŸ”¹ *Bridges the gap between raw analytics and **executive storytelling**.*  

- **`export.py`**  
  âœ… Compiles **charts + insights** into polished **PDF & PPTX reports**.  
  ğŸ”¹ *Delivers **stakeholder-ready outputs** for instant consumption.*  

---

ğŸ’¡ *This modular Python pipeline ensures **scalability, maintainability, and automation**â€”hallmarks of production-grade systems *  

---

## ğŸ““ Notebooks & Visualizations  

The **Jupyter Notebook layer** provides an **exploration sandbox** for analysts and a bridge between raw SQL outputs and interactive dashboards.  

---

### **`visualisation.ipynb`**  
âœ… Contains interactive **Plotly-based visualizations**.  
âœ… Charts are automatically saved as **HTML (for sharing)** and **PNG (for reports)**.  

ğŸ”¹ **Why it matters:** Enables both **exploratory analysis** during development and **stakeholder-ready visuals** for presentations.  

---

### ğŸ“Š Interactive Visuals  

#### â³ **Time-Series Trends**  
- [Impressions Over Time](notebook/chart_image/ts_impressions_by_group.png)  
- [Spend Over Time](notebook/chart_image/ts_spend_by_group.png)  
- [Purchases Over Time](notebook/chart_image/ts_purchases_by_group.png)  
- [Website Clicks Over Time](reports/chart_image/ts_clicks_by_group.png)  

#### ğŸ¥§ **Composition: Spend vs Purchases**  
- [Group A](notebook/chart_image/pie_spend_vs_purchases_A.png)  
- [Group B](notebook/chart_image/pie_spend_vs_purchases_B.png)  

#### ğŸ”„ **Conversion Funnels**  
- [Group A Funnel](notebook/chart_image/funnel_group_A.png)  
- [Group B Funnel](notebook/chart_image/funnel_group_B.png)  

---

ğŸ’¡ *These visualizations transform raw KPIs into **clear, story-driven insights**, helping decision-makers quickly identify trends, bottlenecks, and ROI patterns â€” exactly the type of visualization storytelling.*  

---

## ğŸ“ˆ Results & Insights  

The A/B testing pipeline delivered **clear, data-backed outcomes** for campaign optimization:  

---

### ğŸ”¹ Key Findings  
- ğŸš€ **Group B** consistently outperformed **Group A** across core KPIs:  
  - **+10% higher Conversion Rate**  
  - **Lower Cost per Acquisition (CPA)**  
- ğŸ” Funnel analysis revealed a **critical drop-off in Group A** between *View Content â†’ Add to Cart*.  

---

### ğŸ§­ Strategic Recommendation  
- âœ… **Allocate more budget to Group B** to maximize ROI.  
- âœ… **Optimize mid-funnel performance in Group A** by addressing cart abandonment and improving product engagement.  

---

ğŸ’¡ *This analysis not only identifies the winning variant but also provides **actionable business strategies**â€”demonstrating how data pipelines can directly influence **marketing ROI and decision-making at scale**.*  


## ğŸ›  Tech Stack  

CampAIgn Analytics is built on a **modern, production-ready stack** that balances **data engineering rigor** with **AI-powered automation**.  

- **ğŸ Python 3.10+**  
  âœ… Core pipeline language â€” leveraging **pandas** (data wrangling), **plotly/matplotlib/seaborn** (visualizations), and automation scripts.  

- **ğŸ—„ï¸ SQLite 3.4+**  
  âœ… Lightweight relational database for **reproducible KPI computation** and creation of analytical views.  

- **ğŸ’» VS Code**  
  âœ… Development environment with the **SQLite3 Editor extension** for grid-based query outputs.  

- **ğŸ““ Jupyter Notebooks**  
  âœ… Used for **exploratory data analysis (EDA)**, prototyping, and building **interactive charts**.  

- **ğŸ¤– AI Reporting**  
  âœ… Automates **executive-level reporting** â€” generating insights and exporting stakeholder-ready **PDF & PPTX deliverables**.  

---

ğŸ’¡ *This stack demonstrates mastery of **data engineering, analytics, visualization, and AI automation**â€”the same foundations required to build scalable decision intelligence systems.*  


---

## âš™ï¸ Setup Instructions

1. **Clone the repo**   

       git clone https://github.com/cathelenegeorge/CampAIgn-Analytics.gitcd CampAIgn-Analytics

3. **Create a virtual environment**

       -python -m venv venv   
       -source venv/bin/activate   # Mac/Linux     
       -venv\Scripts\activate      # Windows  
       -pip install -r requirements.txt


4. **Create database schema**

       -sqlite3 sql.db ".read dbms/create_table.sql"


5. **Load cleaned dataset**

       -sqlite3 sql.db ".read dbms/cleanup_and_reload.sql"


6. **Run sanity checks**

       -sqlite3 -header -column sql.db ".read dbms/sanity_checks.sql"


7. **Run full pipeline**

        -python -m src.pipe


Open interactive visuals

Open the PNG files under notebook/chart_image/ see the links above!.

